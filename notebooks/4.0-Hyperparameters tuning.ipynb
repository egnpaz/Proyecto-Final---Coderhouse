{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf11124",
   "metadata": {},
   "source": [
    "#                                  MODELS OPTIMIZATION\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be9c97f",
   "metadata": {},
   "source": [
    "# \n",
    "# Importing libraries needed for the project\n",
    "# ============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a2ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data processing libraries.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importing Scikit Learn library\n",
    "\n",
    "#-. Split the data into train and test data sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -. Models\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn import tree,svm\n",
    "\n",
    "#-.XGBoost Model\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "#-.Metrics\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#-.Hyperparameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612a61d5",
   "metadata": {},
   "source": [
    "# \n",
    "# Importing the data into a DataFrame from our previous cleaned data files.\n",
    "# =============================================================\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "444e31a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heart_Disease</th>\n",
       "      <th>High_BP</th>\n",
       "      <th>High_Chol</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Phys_Activ</th>\n",
       "      <th>Eat_Fruits</th>\n",
       "      <th>Eat_Veg</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Gen_Health</th>\n",
       "      <th>Ment_Health</th>\n",
       "      <th>Phys_Health</th>\n",
       "      <th>Diff_Walk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>280.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>148.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Heart_Disease  High_BP  High_Chol  Weight  BMI  Smoker  Stroke  Diabetes  \\\n",
       "0              0        1          1   280.0   40       1       0         0   \n",
       "1              0        0          0   165.0   25       1       0         0   \n",
       "3              0        1          1   180.0   28       0       0         0   \n",
       "5              0        1          0   145.0   27       0       0         0   \n",
       "6              0        1          1   148.0   24       0       0         0   \n",
       "\n",
       "   Phys_Activ  Eat_Fruits  Eat_Veg  Alcohol  Gen_Health  Ment_Health  \\\n",
       "0           0           0        1        0           5           18   \n",
       "1           1           0        0        0           3            0   \n",
       "3           0           1        0        0           5           30   \n",
       "5           1           1        1        0           2            0   \n",
       "6           1           1        1        0           2            3   \n",
       "\n",
       "   Phys_Health  Diff_Walk  Sex  Age  \n",
       "0           15          1    0    9  \n",
       "1            0          0    0    7  \n",
       "3           30          1    0    9  \n",
       "5            0          0    0   11  \n",
       "6            0          0    0   11  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the data from CSV files in a dataframe.\n",
    "\n",
    "df = pd.read_csv ('heart_disease_clean.csv', index_col= 0)\n",
    "df.head ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86f3407",
   "metadata": {},
   "source": [
    "# \n",
    "# Creating two datsets from the original, one for the terget variable (Y) and other for the dependent variables (X).\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b4a6d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting Data into Dependent and Independetn variables, naming Y to dependent or target variable and x to the independent variables.\n",
    "\n",
    "y = df['Heart_Disease'].copy ()\n",
    "x = df.drop ('Heart_Disease', axis = 1).copy ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b71353",
   "metadata": {},
   "source": [
    "# \n",
    "# ONE-HOT ENCODING. Transforming our categorical variables into dummies.\n",
    "# =============================================================\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4209b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENCODING variables into dummies\n",
    "\n",
    "x_categ = pd.get_dummies (x, columns = ['Diabetes', 'Gen_Health', 'Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1385adb6",
   "metadata": {},
   "source": [
    "# \n",
    "# Spliting Data into Training and Testing Datasets\n",
    "# =============================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a18d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT DATA into TRAIN and TEST sets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split (x_categ, y, random_state = 42, test_size= 0.3,shuffle= True, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5066c60",
   "metadata": {},
   "source": [
    "# \n",
    "#\n",
    "# TUNING THE BASE MODELS HYPERPARAMETERS\n",
    "# ----------------------------------------------------------------------------------------------------------- \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce30cd1",
   "metadata": {},
   "source": [
    "#\n",
    "# 1.-Logistic Regression\n",
    "# =============================================================\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41303a94",
   "metadata": {},
   "source": [
    "# \n",
    "## Create base model for hyperparameter tuning.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "766e1453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity= 14.475574712643677 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#CREATE the LOGISTIC REGRESSION MODEL and FIT IT to the training data\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "#Calculating Accuracy of model\n",
    "\n",
    "lr_y_pred = logreg.predict(x_test)\n",
    "\n",
    "#Sensitivity\n",
    "lr_sen = recall_score(y_test,lr_y_pred)*100\n",
    "print('Sensitivity=', lr_sen,'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac1d4a",
   "metadata": {},
   "source": [
    "# \n",
    "## Hyperparameter tuning with GridSearchCV for Logistic Regression\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7af3aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing the parameters for the parameter grid\n",
    "\n",
    "# Solver\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "#Penalty type\n",
    "penalty = ['l1', 'l2', 'elasticnet', 'none']\n",
    "\n",
    "#C parameter\n",
    "C= np.logspace(-3,3,7)\n",
    "\n",
    "#Class Weight\n",
    "class_weight = np. arange (1,11,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "501fd38c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]), 'class_weight': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])}\n"
     ]
    }
   ],
   "source": [
    "#Creating the parameter grid\n",
    "\n",
    "lr_param_grid = {'solver':solver, 'penalty':penalty, 'C':C, 'class_weight':class_weight}\n",
    "\n",
    "print (lr_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d194209a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1400 candidates, totalling 7000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "3850 fits failed out of a total of 7000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "350 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "350 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "700 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1158, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1169, in _fit_liblinear\n",
      "    class_weight_ = compute_class_weight(class_weight, classes=classes_, y=y)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\class_weight.py\", line 44, in compute_class_weight\n",
      "    if class_weight is None or len(class_weight) == 0:\n",
      "TypeError: object of type 'numpy.int32' has no len()\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "350 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "350 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "350 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "350 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "350 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "350 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1101, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "350 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ...        nan 0.11616799 0.10349414]\n",
      "  warnings.warn(\n",
      "C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;class_weight&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;recall&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;class_weight&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;recall&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'class_weight': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring='recall', verbose=2)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the Grid with previously defined hyperparameters and fiting it to the train data\n",
    "\n",
    "lr_grid = GridSearchCV (estimator = logreg, param_grid = lr_param_grid, cv = 5, verbose = 2, n_jobs = -1 ,scoring = 'recall')\n",
    "lr_grid.fit (x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e7a64175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'class_weight': 1, 'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best parameters\n",
    "\n",
    "lr_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510ed448",
   "metadata": {},
   "source": [
    "# \n",
    "## Training the new model with optimized hyperparameters\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f83f268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity= 14.475574712643677 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#CREATE the OPTIMIZED LOGISTIC REGRESSION MODEL and FIT IT to the training data\n",
    "\n",
    "lr_grid = LogisticRegression(C= 1, class_weight = 1, penalty = 'l2', solver = 'lbfgs')\n",
    "lr_grid.fit(x_train, y_train)\n",
    "#Calculating Accuracy of model\n",
    "\n",
    "lrgrid_y_pred = lr_grid.predict(x_test)\n",
    "\n",
    "#Sensitivity\n",
    "lrgrid_sen = recall_score(y_test,lrgrid_y_pred)*100\n",
    "print('Sensitivity=', lrgrid_sen,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84100dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "import pickle\n",
    "filename = 'lr_grid.sav'\n",
    "pickle.dump(lr_grid, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea1181b",
   "metadata": {},
   "source": [
    "# \n",
    "## Hyperparameter tuning with OPTUNA for Logistic Regression\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "592f2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing optuna library.\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfbfe21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-13 19:11:11,921]\u001b[0m A new study created in memory with name: no-name-2fbc5bac-a0cb-40e1-bfb3-cc1f982e903a\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 19:11:41,683]\u001b[0m Trial 0 finished with value: 0.0966920612462668 and parameters: {'solver': 'saga', 'penalty': 'l2', 'C': 2, 'class_weight': 3}. Best is trial 0 with value: 0.0966920612462668.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 19:12:09,920]\u001b[0m Trial 1 finished with value: 0.10103820306582208 and parameters: {'solver': 'sag', 'penalty': 'none', 'C': 2, 'class_weight': 5}. Best is trial 1 with value: 0.10103820306582208.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 19:12:37,881]\u001b[0m Trial 2 finished with value: 0.10085860536467266 and parameters: {'solver': 'sag', 'penalty': 'none', 'C': 1, 'class_weight': 3}. Best is trial 1 with value: 0.10103820306582208.\u001b[0m\n",
      "\u001b[33m[W 2022-11-13 19:12:38,597]\u001b[0m Trial 3 failed because of the following error: ValueError('\\nAll the 5 fits failed.\\nIt is very likely that your model is misconfigured.\\nYou can try to debug the error by setting error_score=\\'raise\\'.\\n\\nBelow are more details about the failures:\\n--------------------------------------------------------------------------------\\n5 fits failed with the following error:\\nTraceback (most recent call last):\\n  File \"C:\\\\Users\\\\pazen\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\model_selection\\\\_validation.py\", line 686, in _fit_and_score\\n    estimator.fit(X_train, y_train, **fit_params)\\n  File \"C:\\\\Users\\\\pazen\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_logistic.py\", line 1158, in fit\\n    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\\n  File \"C:\\\\Users\\\\pazen\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\svm\\\\_base.py\", line 1169, in _fit_liblinear\\n    class_weight_ = compute_class_weight(class_weight, classes=classes_, y=y)\\n  File \"C:\\\\Users\\\\pazen\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\utils\\\\class_weight.py\", line 44, in compute_class_weight\\n    if class_weight is None or len(class_weight) == 0:\\nTypeError: object of type \\'int\\' has no len()\\n')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\pazen\\AppData\\Local\\Temp/ipykernel_15220/2623454550.py\", line 10, in objective\n",
      "    score = cross_val_score(opt_lr, x, y, n_jobs=4, cv=5, scoring = 'recall')\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 515, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 285, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 367, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1158, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1169, in _fit_liblinear\n",
      "    class_weight_ = compute_class_weight(class_weight, classes=classes_, y=y)\n",
      "  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\class_weight.py\", line 44, in compute_class_weight\n",
      "    if class_weight is None or len(class_weight) == 0:\n",
      "TypeError: object of type 'int' has no len()\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1158, in fit\n    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1169, in _fit_liblinear\n    class_weight_ = compute_class_weight(class_weight, classes=classes_, y=y)\n  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\class_weight.py\", line 44, in compute_class_weight\n    if class_weight is None or len(class_weight) == 0:\nTypeError: object of type 'int' has no len()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15220/2623454550.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \"\"\"\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         _optimize(\n\u001b[0m\u001b[0;32m    420\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             _optimize_sequential(\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     ):\n\u001b[1;32m--> 234\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15220/2623454550.py\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mopt_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'recall'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m     cv_results = cross_validate(\n\u001b[0m\u001b[0;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    283\u001b[0m     )\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m     \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;31m# For callabe scoring, the return type is only know after calling. If the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    365\u001b[0m                 \u001b[1;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             )\n\u001b[1;32m--> 367\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1158, in fit\n    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1169, in _fit_liblinear\n    class_weight_ = compute_class_weight(class_weight, classes=classes_, y=y)\n  File \"C:\\Users\\pazen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\class_weight.py\", line 44, in compute_class_weight\n    if class_weight is None or len(class_weight) == 0:\nTypeError: object of type 'int' has no len()\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    solver = trial.suggest_categorical ('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
    "    penalty = trial.suggest_categorical ('penalty',['l1''l2','elasticnet', 'none'] )\n",
    "    C = trial.suggest_int('C', 1, 3,log = True)\n",
    "    class_weight = trial.suggest_int('class_weight', 1,11)\n",
    "    \n",
    "    opt_lr = LogisticRegression(C= C, class_weight = class_weight, penalty = penalty, solver = solver)\n",
    "    \n",
    "    score = cross_val_score(opt_lr, x, y, n_jobs=4, cv=5, scoring = 'recall')\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78662222",
   "metadata": {},
   "outputs": [],
   "source": [
    "optlr_sen = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b93f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTUNA was not able to run due to incompatibility of sevral of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a39ff63",
   "metadata": {},
   "source": [
    "# \n",
    "# 2. K-Nearest Neighbor\n",
    "# ============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c108e62b",
   "metadata": {},
   "source": [
    "# \n",
    "## Create base model for hyperparameter tuning.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07ec471e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity= 7.483237547892721 %\n"
     ]
    }
   ],
   "source": [
    "#CREATE K-NEAREST NEIGHBOR MODEL and FIT IT to the training data\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "#Calculating Accuracy of model\n",
    "\n",
    "knn_y_pred = knn.predict(x_test)\n",
    "\n",
    "#Sensitivity\n",
    "knn_sen = recall_score(y_test,knn_y_pred)*100\n",
    "print('Sensitivity=', knn_sen,'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ebb277",
   "metadata": {},
   "source": [
    "# \n",
    "## Hyperparameter tuning with GridSearchCV for K-Nearest Neighbor\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db0a96ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing the parameters for the parameter grid\n",
    "\n",
    "# n_neighbors\n",
    "n_neighbors = np.arange (2,11,1)\n",
    "\n",
    "#weights\n",
    "weights = ['uniform', 'distance']\n",
    "\n",
    "#algorithm\n",
    "algorithm = ['auto', 'ball_tree', 'kd_tree',  'brute']\n",
    "\n",
    "#leaf_size\n",
    "leaf_size = np. arange (10,60,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04682bb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10]), 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': array([10, 20, 30, 40, 50])}\n"
     ]
    }
   ],
   "source": [
    "#Creating the parameter grid\n",
    "\n",
    "param_grid = {'n_neighbors':n_neighbors, 'weights':weights, \n",
    "              'algorithm':algorithm, 'leaf_size': leaf_size }\n",
    "\n",
    "print (param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "891067a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;, &#x27;kd_tree&#x27;, &#x27;brute&#x27;],\n",
       "                         &#x27;leaf_size&#x27;: array([10, 20, 30, 40, 50]),\n",
       "                         &#x27;n_neighbors&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "             scoring=&#x27;recall&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;, &#x27;kd_tree&#x27;, &#x27;brute&#x27;],\n",
       "                         &#x27;leaf_size&#x27;: array([10, 20, 30, 40, 50]),\n",
       "                         &#x27;n_neighbors&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "             scoring=&#x27;recall&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
       "                         'leaf_size': array([10, 20, 30, 40, 50]),\n",
       "                         'n_neighbors': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='recall', verbose=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the Grid with previously defined hyperparameters and fiting it to the train data\n",
    "\n",
    "knn_grid = GridSearchCV (estimator = knn, param_grid = param_grid, cv = 5, verbose = 2, n_jobs = -1 ,scoring = 'recall')\n",
    "knn_grid.fit (x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5498e638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'kd_tree',\n",
       " 'leaf_size': 10,\n",
       " 'n_neighbors': 2,\n",
       " 'weights': 'distance'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best parameters\n",
    "\n",
    "knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9098b",
   "metadata": {},
   "source": [
    "# \n",
    "## Training the new model with the GridSearchCV optimized hyperparameters¶\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c01cc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity= 14.307950191570882 %\n"
     ]
    }
   ],
   "source": [
    "#CREATE the OPTIMIZED KNN MODEL and FIT IT to the training data\n",
    "\n",
    "grid_knn = KNeighborsClassifier(n_neighbors =  2, weights = 'distance', algorithm = 'kd_tree', leaf_size = 10 )\n",
    "grid_knn.fit(x_train, y_train)\n",
    "\n",
    "#Calculating Accuracy of optimized model\n",
    "\n",
    "gridknn_y_pred = grid_knn.predict(x_test)\n",
    "\n",
    "#Sensitivity\n",
    "\n",
    "gridknn_sen = recall_score(y_test,gridknn_y_pred)*100\n",
    "print('Sensitivity=', gridknn_sen,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22dca784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "import pickle\n",
    "filename = 'knn_grid.sav'\n",
    "pickle.dump(grid_knn, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb9ef66",
   "metadata": {},
   "source": [
    "# \n",
    "## Hyperparameter tuning with OPTUNA for K-Nearest Neighbor.\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd7cb073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing optuna library.\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9559dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-11 19:21:19,931]\u001b[0m A new study created in memory with name: no-name-732809f3-6385-4e06-877c-835a38f93605\u001b[0m\n",
      "\u001b[32m[I 2022-11-11 19:22:56,862]\u001b[0m Trial 0 finished with value: 0.06957351786263449 and parameters: {'weights': 'distance', 'algorithm': 'auto', 'n_neighbors': 8, 'n_estimators': 950, 'leaf_size': 10}. Best is trial 0 with value: 0.06957351786263449.\u001b[0m\n",
      "\u001b[32m[I 2022-11-11 19:24:34,520]\u001b[0m Trial 1 finished with value: 0.06986084193493126 and parameters: {'weights': 'distance', 'algorithm': 'brute', 'n_neighbors': 7, 'n_estimators': 400, 'leaf_size': 60}. Best is trial 1 with value: 0.06986084193493126.\u001b[0m\n",
      "\u001b[32m[I 2022-11-11 19:26:09,037]\u001b[0m Trial 2 finished with value: 0.15541831655325147 and parameters: {'weights': 'distance', 'algorithm': 'auto', 'n_neighbors': 2, 'n_estimators': 300, 'leaf_size': 30}. Best is trial 2 with value: 0.15541831655325147.\u001b[0m\n",
      "\u001b[32m[I 2022-11-11 19:35:20,484]\u001b[0m Trial 3 finished with value: 0.04198832360171144 and parameters: {'weights': 'uniform', 'algorithm': 'ball_tree', 'n_neighbors': 11, 'n_estimators': 1100, 'leaf_size': 60}. Best is trial 2 with value: 0.15541831655325147.\u001b[0m\n",
      "\u001b[32m[I 2022-11-11 19:35:51,434]\u001b[0m Trial 4 finished with value: 0.04665762518498338 and parameters: {'weights': 'distance', 'algorithm': 'auto', 'n_neighbors': 11, 'n_estimators': 1000, 'leaf_size': 30}. Best is trial 2 with value: 0.15541831655325147.\u001b[0m\n",
      "\u001b[32m[I 2022-11-11 19:36:11,575]\u001b[0m Trial 5 finished with value: 0.07061509423058268 and parameters: {'weights': 'distance', 'algorithm': 'kd_tree', 'n_neighbors': 8, 'n_estimators': 1050, 'leaf_size': 20}. Best is trial 2 with value: 0.15541831655325147.\u001b[0m\n",
      "\u001b[32m[I 2022-11-11 19:36:42,634]\u001b[0m Trial 6 finished with value: 0.0932077497456156 and parameters: {'weights': 'distance', 'algorithm': 'brute', 'n_neighbors': 5, 'n_estimators': 1050, 'leaf_size': 30}. Best is trial 2 with value: 0.15541831655325147.\u001b[0m\n",
      "\u001b[32m[I 2022-11-11 19:37:02,557]\u001b[0m Trial 7 finished with value: 0.08652700550873782 and parameters: {'weights': 'uniform', 'algorithm': 'kd_tree', 'n_neighbors': 5, 'n_estimators': 800, 'leaf_size': 10}. Best is trial 2 with value: 0.15541831655325147.\u001b[0m\n",
      "\u001b[32m[I 2022-11-11 19:37:33,790]\u001b[0m Trial 8 finished with value: 0.11888932447270709 and parameters: {'weights': 'distance', 'algorithm': 'auto', 'n_neighbors': 4, 'n_estimators': 400, 'leaf_size': 50}. Best is trial 2 with value: 0.15541831655325147.\u001b[0m\n",
      "\u001b[32m[I 2022-11-11 19:37:52,664]\u001b[0m Trial 9 finished with value: 0.07133348503518037 and parameters: {'weights': 'distance', 'algorithm': 'kd_tree', 'n_neighbors': 7, 'n_estimators': 900, 'leaf_size': 10}. Best is trial 2 with value: 0.15541831655325147.\u001b[0m\n",
      "\u001b[32m[I 2022-11-11 19:41:18,630]\u001b[0m Trial 10 finished with value: 0.051434898235924245 and parameters: {'weights': 'uniform', 'algorithm': 'ball_tree', 'n_neighbors': 2, 'n_estimators': 600, 'leaf_size': 40}. Best is trial 2 with value: 0.15541831655325147.\u001b[0m\n",
      "\u001b[32m[I 2022-11-11 19:41:49,776]\u001b[0m Trial 11 finished with value: 0.15541831655325147 and parameters: {'weights': 'distance', 'algorithm': 'auto', 'n_neighbors': 2, 'n_estimators': 300, 'leaf_size': 50}. Best is trial 2 with value: 0.15541831655325147.\u001b[0m\n",
      "\u001b[32m[I 2022-11-11 19:42:21,981]\u001b[0m Trial 12 finished with value: 0.15541831655325147 and parameters: {'weights': 'distance', 'algorithm': 'auto', 'n_neighbors': 2, 'n_estimators': 300, 'leaf_size': 40}. Best is trial 2 with value: 0.15541831655325147.\u001b[0m\n",
      "\u001b[32m[I 2022-11-11 19:42:54,275]\u001b[0m Trial 13 finished with value: 0.12998810120886764 and parameters: {'weights': 'distance', 'algorithm': 'auto', 'n_neighbors': 3, 'n_estimators': 600, 'leaf_size': 50}. Best is trial 2 with value: 0.15541831655325147.\u001b[0m\n",
      "\u001b[32m[I 2022-11-11 19:43:26,279]\u001b[0m Trial 14 finished with value: 0.11888932447270709 and parameters: {'weights': 'distance', 'algorithm': 'auto', 'n_neighbors': 4, 'n_estimators': 300, 'leaf_size': 50}. Best is trial 2 with value: 0.15541831655325147.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    weights = trial.suggest_categorical ('weights', ['uniform', 'distance'])\n",
    "    algorithm = trial.suggest_categorical ('algorithm',['auto', 'ball_tree', 'kd_tree',  'brute'] )\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 2, 11)\n",
    "    leaf_size = trial.suggest_int ('leaf_size', 10,60,10)\n",
    "    \n",
    "    opt_knn = KNeighborsClassifier(n_neighbors = n_neighbors, weights = weights, algorithm = algorithm , leaf_size = leaf_size)\n",
    "\n",
    "    score = cross_val_score(opt_knn, x, y, n_jobs=4, cv=5, scoring = 'recall')\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ac7f576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value is : \n",
      "0.15541831655325147\n"
     ]
    }
   ],
   "source": [
    "# Getting the best score:\n",
    "print(f\"The best value is : \\n{study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ce54307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'weights': 'distance', 'algorithm': 'auto', 'n_neighbors': 2, 'n_estimators': 300, 'leaf_size': 30}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9098b",
   "metadata": {},
   "source": [
    "# \n",
    "## Training the new model with the OPTUNA optimized hyperparameters¶\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c01cc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity= 14.39176245210728 %\n"
     ]
    }
   ],
   "source": [
    "#CREATE the OPTIMIZED KNN MODEL and FIT IT to the training data\n",
    "\n",
    "opt_knn = KNeighborsClassifier (n_neighbors =  2, weights = 'distance', algorithm = 'auto', leaf_size = 30)\n",
    "opt_knn.fit(x_train, y_train)\n",
    "\n",
    "#Calculating Accuracy of optimized model\n",
    "\n",
    "optknn_y_pred = opt_knn.predict(x_test)\n",
    "\n",
    "#Sensitivity\n",
    "optknn_sen = recall_score(y_test,optknn_y_pred)*100\n",
    "print('Sensitivity=', optknn_sen,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f99fad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "import pickle\n",
    "filename = 'knn_optuna.sav'\n",
    "pickle.dump(opt_knn, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efd26c3",
   "metadata": {},
   "source": [
    "#\n",
    "# 3.-Random Forest\n",
    "# =============================================================\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f24cfe",
   "metadata": {},
   "source": [
    "# \n",
    "## Create base model for hyperparameter tuning.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd0c8a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity= 12.954980842911878 %\n"
     ]
    }
   ],
   "source": [
    "#CREATE the RANDOM FOREST MODEL and FIT IT to the training data\n",
    "\n",
    "rand_forest = RandomForestClassifier()\n",
    "rand_forest.fit(x_train, y_train)\n",
    "\n",
    "#Calculating Accuracy of model\n",
    "\n",
    "rf_y_pred = rand_forest.predict(x_test)\n",
    "\n",
    "#Sensitivity\n",
    "rf_sen = recall_score(y_test,rf_y_pred)*100\n",
    "print('Sensitivity=', rf_sen,'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac1d4a",
   "metadata": {},
   "source": [
    "# \n",
    "## Hyperparameter tuning with GridSearchCV for Random Forest\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7af3aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing the parameters for the parameter grid\n",
    "\n",
    "# Criterion\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "#Number of trees\n",
    "n_estimators = np.arange (300,1100,50)\n",
    "\n",
    "#Number of features to consider at every split\n",
    "max_features = ['auto' , 'sqrt','log2']\n",
    "\n",
    "#Maximum number of level in the trees\n",
    "max_depth = np. arange (2,10,1)\n",
    "\n",
    "#Minimum samples required to split a node\n",
    "min_samples_split = np.arange (2,6,1)\n",
    "\n",
    "#Minimum samples required at each node\n",
    "min_samples_leaf = [1, 2, 3]\n",
    "\n",
    "#Method for selecting the samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "#Spliting criterion.\n",
    "criterion = ['gini', 'entropy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86734c88",
   "metadata": {},
   "source": [
    "# \n",
    "## ROUND-1\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "501fd38c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': array([ 300,  350,  400,  450,  500,  550,  600,  650,  700,  750,  800,\n",
      "        850,  900,  950, 1000, 1050]), 'max_depth': array([2, 3, 4, 5, 6, 7, 8, 9]), 'min_samples_split': array([2, 3, 4, 5])}\n"
     ]
    }
   ],
   "source": [
    "#Creating the parameter grid\n",
    "\n",
    "rf_param_grid = {'n_estimators':n_estimators, 'max_depth':max_depth, \n",
    "              'min_samples_split':min_samples_split}\n",
    "\n",
    "print (rf_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d194209a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 512 candidates, totalling 2560 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: array([2, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                         &#x27;min_samples_split&#x27;: array([2, 3, 4, 5]),\n",
       "                         &#x27;n_estimators&#x27;: array([ 300,  350,  400,  450,  500,  550,  600,  650,  700,  750,  800,\n",
       "        850,  900,  950, 1000, 1050])},\n",
       "             scoring=&#x27;recall&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: array([2, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                         &#x27;min_samples_split&#x27;: array([2, 3, 4, 5]),\n",
       "                         &#x27;n_estimators&#x27;: array([ 300,  350,  400,  450,  500,  550,  600,  650,  700,  750,  800,\n",
       "        850,  900,  950, 1000, 1050])},\n",
       "             scoring=&#x27;recall&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': array([2, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                         'min_samples_split': array([2, 3, 4, 5]),\n",
       "                         'n_estimators': array([ 300,  350,  400,  450,  500,  550,  600,  650,  700,  750,  800,\n",
       "        850,  900,  950, 1000, 1050])},\n",
       "             scoring='recall', verbose=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the Grid with previously defined hyperparameters and fiting it to the train data\n",
    "\n",
    "rf_grid = GridSearchCV (estimator = rand_forest, param_grid = rf_param_grid, cv = 5, verbose = 2, n_jobs = -1 ,scoring = 'recall')\n",
    "rf_grid.fit (x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7a64175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'min_samples_split': 4, 'n_estimators': 1050}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best parameters\n",
    "\n",
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063cd25a",
   "metadata": {},
   "source": [
    "# \n",
    "## Training the new model with ROUND 1 optimized hyperparameters\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "094cfa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity= 3.148946360153257 %\n"
     ]
    }
   ],
   "source": [
    "#CREATE the OPTIMIZED RANDOM FOREST MODEL and FIT IT to the training data\n",
    "\n",
    "grid_rf = RandomForestClassifier (n_estimators=1050, max_depth= 9, min_samples_split= 4)\n",
    "grid_rf.fit(x_train, y_train)\n",
    "\n",
    "#Calculating Accuracy of optimized model\n",
    "\n",
    "grid_rf_y_pred = grid_rf.predict(x_test)\n",
    "\n",
    "#Sensitivity\n",
    "grid_rf_sen = recall_score(y_test,grid_rf_y_pred)*100\n",
    "print('Sensitivity=', grid_rf_sen,'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19206be",
   "metadata": {},
   "source": [
    "# \n",
    "## ROUND-2\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a5112ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the parameter grid\n",
    "\n",
    "param_grid = {'criterion':criterion, 'bootstrap':bootstrap, \n",
    "              'max_features': max_features, 'min_samples_leaf':min_samples_leaf}\n",
    "\n",
    "print (param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "741230c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(max_depth=9, min_samples_split=4,\n",
       "                                              n_estimators=1050),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;bootstrap&#x27;: [True, False],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                         &#x27;min_samples_split&#x27;: array([2, 3, 4, 5])},\n",
       "             scoring=&#x27;recall&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(max_depth=9, min_samples_split=4,\n",
       "                                              n_estimators=1050),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;bootstrap&#x27;: [True, False],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                         &#x27;min_samples_split&#x27;: array([2, 3, 4, 5])},\n",
       "             scoring=&#x27;recall&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=9, min_samples_split=4, n_estimators=1050)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=9, min_samples_split=4, n_estimators=1050)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(max_depth=9, min_samples_split=4,\n",
       "                                              n_estimators=1050),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'min_samples_split': array([2, 3, 4, 5])},\n",
       "             scoring='recall', verbose=2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the Grid with previously defined hyperparameters and fiting it to the train data\n",
    "\n",
    "rf_grid2 = GridSearchCV (estimator = grid_rf, param_grid = param_grid, cv = 5, verbose = 2, n_jobs = -1 ,scoring = 'recall')\n",
    "rf_grid2.fit (x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d96a6da9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'gini',\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best parameters\n",
    "\n",
    "rf_grid2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063cd25a",
   "metadata": {},
   "source": [
    "# \n",
    "## Training the new model with all the GridSearchCV optimized hyperparameters\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2fccb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity= 3.148946360153257 %\n"
     ]
    }
   ],
   "source": [
    "#CREATE the OPTIMIZED RANDOM FOREST MODEL and FIT IT to the training data\n",
    "\n",
    "grid2_rf = RandomForestClassifier (n_estimators=1050, max_depth= 9, min_samples_split= 4, bootstrap = False, criterion = 'gini',\n",
    "                                  max_features = 'log2', min_samples_leaf = 2)\n",
    "grid2_rf.fit(x_train, y_train)\n",
    "\n",
    "#Calculating Accuracy of optimized model\n",
    "\n",
    "grid2rf_y_pred = grid2_rf.predict(x_test)\n",
    "\n",
    "#Sensitivity\n",
    "grid2rf_sen = recall_score(y_test,grid2_rf_y_pred)*100\n",
    "print('Sensitivity=', grid2rf_sen,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d84f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "import pickle\n",
    "filename = 'rf_grid.sav'\n",
    "pickle.dump(grid2_rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821fa976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bea1181b",
   "metadata": {},
   "source": [
    "# \n",
    "## Hyperparameter tuning with OPTUNA for Random Forest\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "592f2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing optuna library.\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfbfe21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-12 15:00:47,442]\u001b[0m A new study created in memory with name: no-name-91f6320b-bdc8-44ac-9a21-04bd1a3e9d4a\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:19:53,978]\u001b[0m Trial 0 finished with value: 0.023490444073617705 and parameters: {'criterion': 'entropy', 'max_features': 'sqrt', 'max_depth': 6, 'n_estimators': 3000, 'min_samples_split': 5, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 0 with value: 0.023490444073617705.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:24:23,723]\u001b[0m Trial 1 finished with value: 0.0020833333333333333 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'n_estimators': 1500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 0 with value: 0.023490444073617705.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:29:29,277]\u001b[0m Trial 2 finished with value: 0.009446406936592757 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'n_estimators': 1400, 'min_samples_split': 2, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 0 with value: 0.023490444073617705.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:35:33,771]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_features': 'auto', 'max_depth': 3, 'n_estimators': 2350, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 0 with value: 0.023490444073617705.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:38:59,470]\u001b[0m Trial 4 finished with value: 0.009877473668893692 and parameters: {'criterion': 'entropy', 'max_features': 'log2', 'max_depth': 5, 'n_estimators': 950, 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 0 with value: 0.023490444073617705.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:40:36,097]\u001b[0m Trial 5 finished with value: 0.026004682891540405 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'n_estimators': 400, 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 5 with value: 0.026004682891540405.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:43:55,610]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_features': 'auto', 'max_depth': 2, 'n_estimators': 1800, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 5 with value: 0.026004682891540405.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:47:05,813]\u001b[0m Trial 7 finished with value: 0.0 and parameters: {'criterion': 'entropy', 'max_features': 'auto', 'max_depth': 2, 'n_estimators': 1650, 'min_samples_split': 2, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 5 with value: 0.026004682891540405.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:52:14,055]\u001b[0m Trial 8 finished with value: 0.02600477964016735 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 6, 'n_estimators': 1250, 'min_samples_split': 3, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 8 with value: 0.02600477964016735.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:56:40,560]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 2, 'n_estimators': 2400, 'min_samples_split': 6, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 8 with value: 0.02600477964016735.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:58:32,774]\u001b[0m Trial 10 finished with value: 0.0 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 3, 'n_estimators': 750, 'min_samples_split': 4, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 8 with value: 0.02600477964016735.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 15:59:53,062]\u001b[0m Trial 11 finished with value: 0.03552294825831832 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 7, 'n_estimators': 300, 'min_samples_split': 4, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 11 with value: 0.03552294825831832.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:01:11,451]\u001b[0m Trial 12 finished with value: 0.03505603293478059 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 7, 'n_estimators': 300, 'min_samples_split': 4, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 11 with value: 0.03552294825831832.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:02:57,181]\u001b[0m Trial 13 finished with value: 0.034984251903496986 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 7, 'n_estimators': 400, 'min_samples_split': 4, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 11 with value: 0.03552294825831832.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 16:05:08,878]\u001b[0m Trial 14 finished with value: 0.0027656820494403544 and parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 4, 'n_estimators': 750, 'min_samples_split': 3, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 11 with value: 0.03552294825831832.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    criterion = trial.suggest_categorical ('criterion', ['gini', 'entropy'])\n",
    "    max_features = trial.suggest_categorical ('max_features',['auto', 'sqrt','log2'] )\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 7, log=True)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 300,3000,50)\n",
    "    min_samples_split = trial.suggest_int ('min_samples_split', 2,6)\n",
    "    min_samples_leaf = trial.suggest_int ('min_samples_leaf', 1,5)\n",
    "    bootstrap = trial.suggest_categorical ('bootstrap', [True, False])\n",
    "\n",
    "    opt_rf = RandomForestClassifier(criterion =criterion, min_samples_leaf = min_samples_leaf,\n",
    "            max_depth=max_depth, n_estimators=n_estimators,min_samples_split=min_samples_split, \n",
    "                                max_features = max_features, bootstrap = bootstrap)\n",
    "\n",
    "    score = cross_val_score(opt_rf, x, y, n_jobs=4, cv=5, scoring = 'recall')\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ac7f576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value is : \n",
      "0.03552294825831832\n"
     ]
    }
   ],
   "source": [
    "# Getting the best score:\n",
    "print(f\"The best value is : \\n{study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ce54307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'criterion': 'gini', 'max_features': 'sqrt', 'max_depth': 7, 'n_estimators': 300, 'min_samples_split': 4, 'min_samples_leaf': 5, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9098b",
   "metadata": {},
   "source": [
    "# \n",
    "## Training the new model with the OPTUNA optimized hyperparameters¶\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c01cc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity= 2.1551724137931036 %\n"
     ]
    }
   ],
   "source": [
    "#CREATE the OPTIMIZED RANDOM FOREST MODEL and FIT IT to the training data\n",
    "\n",
    "opt_rf = RandomForestClassifier (max_features = 'sqrt', n_estimators=300, max_depth= 7, min_samples_split= 4, criterion= 'gini', bootstrap = True, min_samples_leaf = 5)\n",
    "opt_rf.fit(x_train, y_train)\n",
    "\n",
    "#Calculating Accuracy of optimized model\n",
    "\n",
    "optrf_y_pred = opt_rf.predict(x_test)\n",
    "\n",
    "#Sensitivity\n",
    "optrf_sen = recall_score(y_test,optrf_y_pred)*100\n",
    "print('Sensitivity=', optrf_sen,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fa8fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "import pickle\n",
    "filename = 'rf_optuna.sav'\n",
    "pickle.dump(opt_rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a39ff63",
   "metadata": {},
   "source": [
    "# \n",
    "# 4. XGBoost\n",
    "# ============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41303a94",
   "metadata": {},
   "source": [
    "# \n",
    "## Create base model for hyperparameter tuning.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07ec471e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-aucpr:0.31653\n",
      "[1]\tvalidation_0-aucpr:0.32745\n",
      "[2]\tvalidation_0-aucpr:0.33300\n",
      "[3]\tvalidation_0-aucpr:0.34011\n",
      "[4]\tvalidation_0-aucpr:0.34317\n",
      "[5]\tvalidation_0-aucpr:0.34726\n",
      "[6]\tvalidation_0-aucpr:0.35199\n",
      "[7]\tvalidation_0-aucpr:0.35506\n",
      "[8]\tvalidation_0-aucpr:0.35627\n",
      "[9]\tvalidation_0-aucpr:0.35784\n",
      "[10]\tvalidation_0-aucpr:0.35892\n",
      "[11]\tvalidation_0-aucpr:0.36048\n",
      "[12]\tvalidation_0-aucpr:0.36159\n",
      "[13]\tvalidation_0-aucpr:0.36238\n",
      "[14]\tvalidation_0-aucpr:0.36260\n",
      "[15]\tvalidation_0-aucpr:0.36339\n",
      "[16]\tvalidation_0-aucpr:0.36374\n",
      "[17]\tvalidation_0-aucpr:0.36399\n",
      "[18]\tvalidation_0-aucpr:0.36456\n",
      "[19]\tvalidation_0-aucpr:0.36456\n",
      "[20]\tvalidation_0-aucpr:0.36491\n",
      "[21]\tvalidation_0-aucpr:0.36517\n",
      "[22]\tvalidation_0-aucpr:0.36529\n",
      "[23]\tvalidation_0-aucpr:0.36547\n",
      "[24]\tvalidation_0-aucpr:0.36544\n",
      "[25]\tvalidation_0-aucpr:0.36556\n",
      "[26]\tvalidation_0-aucpr:0.36549\n",
      "[27]\tvalidation_0-aucpr:0.36537\n",
      "[28]\tvalidation_0-aucpr:0.36514\n",
      "[29]\tvalidation_0-aucpr:0.36526\n",
      "[30]\tvalidation_0-aucpr:0.36524\n",
      "[31]\tvalidation_0-aucpr:0.36517\n",
      "[32]\tvalidation_0-aucpr:0.36507\n",
      "[33]\tvalidation_0-aucpr:0.36496\n",
      "[34]\tvalidation_0-aucpr:0.36511\n",
      "[35]\tvalidation_0-aucpr:0.36470\n",
      "Sensitivity= 9.530651340996169 %\n"
     ]
    }
   ],
   "source": [
    "#CREATE XGBOOST model and FIT IT to the training data\n",
    "\n",
    "\n",
    "xgboost = xgb.XGBClassifier (objective = 'binary:logistic', seed = 42, use_label_encoder=False)\n",
    "xgboost.fit (x_train, y_train, verbose = True, early_stopping_rounds = 10, eval_metric = 'aucpr', \n",
    "             eval_set = ([(x_test, y_test)]))\n",
    "\n",
    "#Calculating Accuracy of model\n",
    "\n",
    "xgb_y_pred = xgboost.predict(x_test)\n",
    "\n",
    "#Sensitivity\n",
    "xgb_sen = recall_score(y_test,xgb_y_pred)*100\n",
    "print('Sensitivity=', xgb_sen,'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac1d4a",
   "metadata": {},
   "source": [
    "# \n",
    "## Hyperparameter tuning with GridSearchCV for XGBoost.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7af3aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing the parameters for the parameter grid\n",
    "\n",
    "#Maximum number of level in the trees\n",
    "max_depth = np. arange (2,15,2)\n",
    "\n",
    "#Learning rate\n",
    "learning_rate = (0.05,0.10,0.15,0.20,0.25,0.30)\n",
    "\n",
    "#Minimum Child Weight\n",
    "min_child_weight = (1,3,5,7)\n",
    "\n",
    "#Gamma\n",
    "gamma = (0.0,0.1,0.2,0.3,0.4)\n",
    "\n",
    "#Columns Sampled by Tree.\n",
    "colsample_bytree = (0.3,0.4,0.5,0.6,0.7)\n",
    "\n",
    "# Scale Post Weight\n",
    "scale_pos_weight = (1,3,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4b8ad2",
   "metadata": {},
   "source": [
    "# \n",
    "## ROUND 1\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "501fd38c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': array([ 2,  4,  6,  8, 10, 12, 14]), 'learning_rate': (0.05, 0.1, 0.15, 0.2, 0.25, 0.3), 'min_child_weight': (1, 3, 5, 7)}\n"
     ]
    }
   ],
   "source": [
    "#Creating the parameter grid\n",
    "\n",
    "param_grid = {'max_depth':max_depth, 'learning_rate':learning_rate, \n",
    "              'min_child_weight':min_child_weight}\n",
    "\n",
    "print (param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d194209a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 168 candidates, totalling 840 fits\n",
      "[22:20:49] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1,\n",
       "                                     enable_categorical=False, gamma=0,\n",
       "                                     gpu_id=-1, importance_type=None,\n",
       "                                     interaction_constraints=&#x27;&#x27;,\n",
       "                                     learning_rate=0.300000012,\n",
       "                                     max_delta_step=0, max_depth=6,\n",
       "                                     min_child_weight=1, missing=nan,\n",
       "                                     monotone_constraints=&#x27;()&#x27;,\n",
       "                                     n_estimators=10...\n",
       "                                     num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "                                     random_state=42, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=42, subsample=1,\n",
       "                                     tree_method=&#x27;exact&#x27;,\n",
       "                                     use_label_encoder=False,\n",
       "                                     validate_parameters=1, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: (0.05, 0.1, 0.15, 0.2, 0.25, 0.3),\n",
       "                         &#x27;max_depth&#x27;: array([ 2,  4,  6,  8, 10, 12, 14]),\n",
       "                         &#x27;min_child_weight&#x27;: (1, 3, 5, 7)},\n",
       "             scoring=&#x27;recall&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1,\n",
       "                                     enable_categorical=False, gamma=0,\n",
       "                                     gpu_id=-1, importance_type=None,\n",
       "                                     interaction_constraints=&#x27;&#x27;,\n",
       "                                     learning_rate=0.300000012,\n",
       "                                     max_delta_step=0, max_depth=6,\n",
       "                                     min_child_weight=1, missing=nan,\n",
       "                                     monotone_constraints=&#x27;()&#x27;,\n",
       "                                     n_estimators=10...\n",
       "                                     num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "                                     random_state=42, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=42, subsample=1,\n",
       "                                     tree_method=&#x27;exact&#x27;,\n",
       "                                     use_label_encoder=False,\n",
       "                                     validate_parameters=1, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: (0.05, 0.1, 0.15, 0.2, 0.25, 0.3),\n",
       "                         &#x27;max_depth&#x27;: array([ 2,  4,  6,  8, 10, 12, 14]),\n",
       "                         &#x27;min_child_weight&#x27;: (1, 3, 5, 7)},\n",
       "             scoring=&#x27;recall&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=16,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              subsample=1, tree_method=&#x27;exact&#x27;, use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=16,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              subsample=1, tree_method=&#x27;exact&#x27;, use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1,\n",
       "                                     enable_categorical=False, gamma=0,\n",
       "                                     gpu_id=-1, importance_type=None,\n",
       "                                     interaction_constraints='',\n",
       "                                     learning_rate=0.300000012,\n",
       "                                     max_delta_step=0, max_depth=6,\n",
       "                                     min_child_weight=1, missing=nan,\n",
       "                                     monotone_constraints='()',\n",
       "                                     n_estimators=10...\n",
       "                                     num_parallel_tree=1, predictor='auto',\n",
       "                                     random_state=42, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=42, subsample=1,\n",
       "                                     tree_method='exact',\n",
       "                                     use_label_encoder=False,\n",
       "                                     validate_parameters=1, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': (0.05, 0.1, 0.15, 0.2, 0.25, 0.3),\n",
       "                         'max_depth': array([ 2,  4,  6,  8, 10, 12, 14]),\n",
       "                         'min_child_weight': (1, 3, 5, 7)},\n",
       "             scoring='recall', verbose=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the Grid with previously defined hyperparameters and fiting it to the train data\n",
    "\n",
    "xgb_grid = GridSearchCV (estimator = xgboost, param_grid = param_grid, cv = 5, verbose = 2, n_jobs = -1 ,scoring = 'recall')\n",
    "xgb_grid.fit (x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7a64175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.3, 'max_depth': 14, 'min_child_weight': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best parameters\n",
    "\n",
    "xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9098b",
   "metadata": {},
   "source": [
    "# \n",
    "## Training the new model with the ROUND 1 optimized hyperparameters¶\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07ec471e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-aucpr:0.31075\n",
      "[1]\tvalidation_0-aucpr:0.31780\n",
      "[2]\tvalidation_0-aucpr:0.31918\n",
      "[3]\tvalidation_0-aucpr:0.32138\n",
      "[4]\tvalidation_0-aucpr:0.32226\n",
      "[5]\tvalidation_0-aucpr:0.32344\n",
      "[6]\tvalidation_0-aucpr:0.32369\n",
      "[7]\tvalidation_0-aucpr:0.32395\n",
      "[8]\tvalidation_0-aucpr:0.32424\n",
      "[9]\tvalidation_0-aucpr:0.32526\n",
      "[10]\tvalidation_0-aucpr:0.32588\n",
      "[11]\tvalidation_0-aucpr:0.32644\n",
      "[12]\tvalidation_0-aucpr:0.32620\n",
      "[13]\tvalidation_0-aucpr:0.32694\n",
      "[14]\tvalidation_0-aucpr:0.32643\n",
      "[15]\tvalidation_0-aucpr:0.32666\n",
      "[16]\tvalidation_0-aucpr:0.32684\n",
      "[17]\tvalidation_0-aucpr:0.32628\n",
      "[18]\tvalidation_0-aucpr:0.32613\n",
      "[19]\tvalidation_0-aucpr:0.32629\n",
      "[20]\tvalidation_0-aucpr:0.32616\n",
      "[21]\tvalidation_0-aucpr:0.32602\n",
      "[22]\tvalidation_0-aucpr:0.32527\n",
      "[23]\tvalidation_0-aucpr:0.32459\n",
      "Sensitivity= 12.176724137931034 %\n"
     ]
    }
   ],
   "source": [
    "#CREATE OPTIMIZED XGBOOST model and FIT IT to the training data\n",
    "\n",
    "\n",
    "grid_xgb = xgb.XGBClassifier (objective = 'binary:logistic', seed = 42, use_label_encoder=False, learning_rate = 0.3, \n",
    "                            max_depth = 14, min_child_weight = 1)\n",
    "grid_xgb.fit (x_train, y_train, verbose = True, early_stopping_rounds = 10, eval_metric = 'aucpr', \n",
    "             eval_set = ([(x_test, y_test)]))\n",
    "\n",
    "#Calculating Accuracy of model\n",
    "\n",
    "gridxgb_y_pred = grid_xgb.predict(x_test)\n",
    "\n",
    "#Sensitivity\n",
    "gridxgb_sen = recall_score(y_test,gridxgb_y_pred)*100\n",
    "print('Sensitivity=', gridxgb_sen,'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de47a6",
   "metadata": {},
   "source": [
    "# \n",
    "## ROUND 2\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "501fd38c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scale_pos_weight': (1, 3, 5), 'gamma': (0.0, 0.1, 0.2, 0.3, 0.4), 'colsample_bytree': (0.3, 0.4, 0.5, 0.6, 0.7)}\n"
     ]
    }
   ],
   "source": [
    "#Creating the parameter grid \n",
    "\n",
    "param_grid2 = {'scale_pos_weight': scale_pos_weight, 'gamma': gamma, 'colsample_bytree': colsample_bytree }\n",
    "\n",
    "print (param_grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d194209a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 75 candidates, totalling 375 fits\n",
      "[13:46:45] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1,\n",
       "                                     enable_categorical=False, gamma=0,\n",
       "                                     gpu_id=-1, importance_type=None,\n",
       "                                     interaction_constraints=&#x27;&#x27;,\n",
       "                                     learning_rate=0.3, max_delta_step=0,\n",
       "                                     max_depth=14, min_child_weight=1,\n",
       "                                     missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "                                     n_estimators=100, n_jobs=16,\n",
       "                                     num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "                                     random_state=42, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=42, subsample=1,\n",
       "                                     tree_method=&#x27;exact&#x27;,\n",
       "                                     use_label_encoder=False,\n",
       "                                     validate_parameters=1, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: (0.3, 0.4, 0.5, 0.6, 0.7),\n",
       "                         &#x27;gamma&#x27;: (0.0, 0.1, 0.2, 0.3, 0.4),\n",
       "                         &#x27;scale_pos_weight&#x27;: (1, 3, 5)},\n",
       "             scoring=&#x27;recall&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1,\n",
       "                                     enable_categorical=False, gamma=0,\n",
       "                                     gpu_id=-1, importance_type=None,\n",
       "                                     interaction_constraints=&#x27;&#x27;,\n",
       "                                     learning_rate=0.3, max_delta_step=0,\n",
       "                                     max_depth=14, min_child_weight=1,\n",
       "                                     missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "                                     n_estimators=100, n_jobs=16,\n",
       "                                     num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "                                     random_state=42, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=42, subsample=1,\n",
       "                                     tree_method=&#x27;exact&#x27;,\n",
       "                                     use_label_encoder=False,\n",
       "                                     validate_parameters=1, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: (0.3, 0.4, 0.5, 0.6, 0.7),\n",
       "                         &#x27;gamma&#x27;: (0.0, 0.1, 0.2, 0.3, 0.4),\n",
       "                         &#x27;scale_pos_weight&#x27;: (1, 3, 5)},\n",
       "             scoring=&#x27;recall&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.3, max_delta_step=0,\n",
       "              max_depth=14, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=16,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              subsample=1, tree_method=&#x27;exact&#x27;, use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.3, max_delta_step=0,\n",
       "              max_depth=14, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=16,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              subsample=1, tree_method=&#x27;exact&#x27;, use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1,\n",
       "                                     enable_categorical=False, gamma=0,\n",
       "                                     gpu_id=-1, importance_type=None,\n",
       "                                     interaction_constraints='',\n",
       "                                     learning_rate=0.3, max_delta_step=0,\n",
       "                                     max_depth=14, min_child_weight=1,\n",
       "                                     missing=nan, monotone_constraints='()',\n",
       "                                     n_estimators=100, n_jobs=16,\n",
       "                                     num_parallel_tree=1, predictor='auto',\n",
       "                                     random_state=42, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=42, subsample=1,\n",
       "                                     tree_method='exact',\n",
       "                                     use_label_encoder=False,\n",
       "                                     validate_parameters=1, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': (0.3, 0.4, 0.5, 0.6, 0.7),\n",
       "                         'gamma': (0.0, 0.1, 0.2, 0.3, 0.4),\n",
       "                         'scale_pos_weight': (1, 3, 5)},\n",
       "             scoring='recall', verbose=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the Grid with previously defined hyperparameters and fiting it to the train data\n",
    "\n",
    "xgb_grid2 = GridSearchCV (estimator = grid_xgb, param_grid = param_grid2, cv = 5, verbose = 2, n_jobs = -1 ,scoring = 'recall')\n",
    "xgb_grid2.fit (x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7a64175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.3, 'gamma': 0.2, 'scale_pos_weight': 5}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best parameters\n",
    "\n",
    "xgb_grid2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9098b",
   "metadata": {},
   "source": [
    "# \n",
    "## Training the new model with all the GridSearchCV optimized hyperparameters¶\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07ec471e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-aucpr:0.20394\n",
      "[1]\tvalidation_0-aucpr:0.28027\n",
      "[2]\tvalidation_0-aucpr:0.29643\n",
      "[3]\tvalidation_0-aucpr:0.30692\n",
      "[4]\tvalidation_0-aucpr:0.31604\n",
      "[5]\tvalidation_0-aucpr:0.32108\n",
      "[6]\tvalidation_0-aucpr:0.32066\n",
      "[7]\tvalidation_0-aucpr:0.33267\n",
      "[8]\tvalidation_0-aucpr:0.33553\n",
      "[9]\tvalidation_0-aucpr:0.33784\n",
      "[10]\tvalidation_0-aucpr:0.33704\n",
      "[11]\tvalidation_0-aucpr:0.33703\n",
      "[12]\tvalidation_0-aucpr:0.33818\n",
      "[13]\tvalidation_0-aucpr:0.33924\n",
      "[14]\tvalidation_0-aucpr:0.34023\n",
      "[15]\tvalidation_0-aucpr:0.34195\n",
      "[16]\tvalidation_0-aucpr:0.34251\n",
      "[17]\tvalidation_0-aucpr:0.34345\n",
      "[18]\tvalidation_0-aucpr:0.34439\n",
      "[19]\tvalidation_0-aucpr:0.34502\n",
      "[20]\tvalidation_0-aucpr:0.34510\n",
      "[21]\tvalidation_0-aucpr:0.34293\n",
      "[22]\tvalidation_0-aucpr:0.34318\n",
      "[23]\tvalidation_0-aucpr:0.34341\n",
      "[24]\tvalidation_0-aucpr:0.34363\n",
      "[25]\tvalidation_0-aucpr:0.34244\n",
      "[26]\tvalidation_0-aucpr:0.34011\n",
      "[27]\tvalidation_0-aucpr:0.34025\n",
      "[28]\tvalidation_0-aucpr:0.33938\n",
      "[29]\tvalidation_0-aucpr:0.33932\n",
      "[30]\tvalidation_0-aucpr:0.33719\n",
      "Sensitivity= 54.525862068965516 %\n"
     ]
    }
   ],
   "source": [
    "#CREATE OPTIMIZED XGBOOST model and FIT IT to the training data\n",
    "\n",
    "\n",
    "xgb_grid2 = xgb.XGBClassifier (objective = 'binary:logistic', seed = 42, use_label_encoder=False, learning_rate = 0.3, \n",
    "                            max_depth = 14, min_child_weight = 1, colsample_bytree = 0.3, gamma = 0.2, scale_pos_weight = 5)\n",
    "xgb_grid2.fit (x_train, y_train, verbose = True, early_stopping_rounds = 10, eval_metric = 'aucpr', \n",
    "             eval_set = ([(x_test, y_test)]))\n",
    "\n",
    "#Calculating Accuracy of model\n",
    "\n",
    "xgbgrid2_y_pred = xgb_grid2.predict(x_test)\n",
    "\n",
    "#Sensitivity\n",
    "xgbgrid2_sen = recall_score(y_test,xgbgrid2_y_pred)*100\n",
    "print('Sensitivity=', xgbgrid2_sen,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fa8fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "import pickle\n",
    "filename = 'xgb_grid.sav'\n",
    "pickle.dump(xgb_grid2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea1181b",
   "metadata": {},
   "source": [
    "# \n",
    "## Hyperparameter tuning with OPTUNA for XGBoost.\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "592f2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing optuna library.\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48aa3ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-12 14:48:59,618]\u001b[0m A new study created in memory with name: no-name-f7b67d2f-46c1-4efa-a0d6-6f47a1a4496c\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:49:09,547]\u001b[0m Trial 0 finished with value: 0.8369307826783322 and parameters: {'max_depth': 5, 'min_child_weight': 11, 'gamma': 0.05492940075967834, 'colsample_bytree': 0.847302733427076, 'scale_pos_weight': 11, 'learning_rate': 0.13220759527405818}. Best is trial 0 with value: 0.8369307826783322.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:49:15,512]\u001b[0m Trial 1 finished with value: 0.5671130777312008 and parameters: {'max_depth': 4, 'min_child_weight': 8, 'gamma': 0.179663942890913, 'colsample_bytree': 0.6120208721432394, 'scale_pos_weight': 4, 'learning_rate': 0.3859880033847078}. Best is trial 0 with value: 0.8369307826783322.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:49:27,333]\u001b[0m Trial 2 finished with value: 0.762975306654448 and parameters: {'max_depth': 7, 'min_child_weight': 15, 'gamma': 0.14416310962444653, 'colsample_bytree': 0.729259999015774, 'scale_pos_weight': 8, 'learning_rate': 0.10817958095226844}. Best is trial 0 with value: 0.8369307826783322.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:49:31,211]\u001b[0m Trial 3 finished with value: 0.6189432263577316 and parameters: {'max_depth': 2, 'min_child_weight': 12, 'gamma': 0.16934518364762213, 'colsample_bytree': 0.8133056222948505, 'scale_pos_weight': 5, 'learning_rate': 0.09562335313274803}. Best is trial 0 with value: 0.8369307826783322.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:49:39,142]\u001b[0m Trial 4 finished with value: 0.7529181514355949 and parameters: {'max_depth': 6, 'min_child_weight': 9, 'gamma': 0.029260020359070715, 'colsample_bytree': 0.4205828796334719, 'scale_pos_weight': 8, 'learning_rate': 0.3284917928456991}. Best is trial 0 with value: 0.8369307826783322.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:49:45,302]\u001b[0m Trial 5 finished with value: 0.8331593793020889 and parameters: {'max_depth': 5, 'min_child_weight': 2, 'gamma': 0.3319653746208084, 'colsample_bytree': 0.32215853336285244, 'scale_pos_weight': 11, 'learning_rate': 0.1685539237663286}. Best is trial 0 with value: 0.8369307826783322.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:49:53,892]\u001b[0m Trial 6 finished with value: 0.8355300947568953 and parameters: {'max_depth': 5, 'min_child_weight': 2, 'gamma': 0.21395572026007137, 'colsample_bytree': 0.8858294601747934, 'scale_pos_weight': 11, 'learning_rate': 0.14882111755912641}. Best is trial 0 with value: 0.8369307826783322.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:50:08,815]\u001b[0m Trial 7 finished with value: 0.28932126065266883 and parameters: {'max_depth': 8, 'min_child_weight': 2, 'gamma': 0.1553359656424804, 'colsample_bytree': 0.8907861383442972, 'scale_pos_weight': 2, 'learning_rate': 0.3330778436326628}. Best is trial 0 with value: 0.8369307826783322.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:50:13,101]\u001b[0m Trial 8 finished with value: 0.4541140483134263 and parameters: {'max_depth': 3, 'min_child_weight': 4, 'gamma': 0.08824427547903509, 'colsample_bytree': 0.3102891339865832, 'scale_pos_weight': 3, 'learning_rate': 0.1563328214114321}. Best is trial 0 with value: 0.8369307826783322.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:50:18,180]\u001b[0m Trial 9 finished with value: 0.8395886222582728 and parameters: {'max_depth': 3, 'min_child_weight': 4, 'gamma': 0.31697002808481123, 'colsample_bytree': 0.732879490463523, 'scale_pos_weight': 11, 'learning_rate': 0.13164217591978739}. Best is trial 9 with value: 0.8395886222582728.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:50:41,483]\u001b[0m Trial 10 finished with value: 0.44290775160318924 and parameters: {'max_depth': 13, 'min_child_weight': 6, 'gamma': 0.3870641161955599, 'colsample_bytree': 0.6146196492070918, 'scale_pos_weight': 8, 'learning_rate': 0.4611795456090113}. Best is trial 9 with value: 0.8395886222582728.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:50:45,135]\u001b[0m Trial 11 finished with value: 0.8170320862306323 and parameters: {'max_depth': 2, 'min_child_weight': 11, 'gamma': 0.2847894847212733, 'colsample_bytree': 0.7278030199798157, 'scale_pos_weight': 10, 'learning_rate': 0.23906846238065246}. Best is trial 9 with value: 0.8395886222582728.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:50:50,222]\u001b[0m Trial 12 finished with value: 0.8027008282198459 and parameters: {'max_depth': 3, 'min_child_weight': 6, 'gamma': 0.2608181045996687, 'colsample_bytree': 0.7497656612669777, 'scale_pos_weight': 9, 'learning_rate': 0.05963963645808487}. Best is trial 9 with value: 0.8395886222582728.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:50:55,335]\u001b[0m Trial 13 finished with value: 0.7414601341477762 and parameters: {'max_depth': 3, 'min_child_weight': 14, 'gamma': 0.012722942478879805, 'colsample_bytree': 0.8055687365522359, 'scale_pos_weight': 7, 'learning_rate': 0.21825127171044456}. Best is trial 9 with value: 0.8395886222582728.\u001b[0m\n",
      "\u001b[32m[I 2022-11-12 14:51:08,650]\u001b[0m Trial 14 finished with value: 0.7971334349322914 and parameters: {'max_depth': 9, 'min_child_weight': 10, 'gamma': 0.07987848452743081, 'colsample_bytree': 0.5065866845247579, 'scale_pos_weight': 10, 'learning_rate': 0.05058433813418084}. Best is trial 9 with value: 0.8395886222582728.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    max_depth = trial.suggest_int('max_depth', 2, 15, log=True)\n",
    "    min_child_weight =  trial.suggest_int('min_child_weight', 1,15)\n",
    "    gamma = trial.suggest_float ('gamma', 0,0.4)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.3,0.9)\n",
    "    scale_pos_weight = trial.suggest_int ('scale_pos_weight', 1,11)\n",
    "    learning_rate = trial.suggest_float ('learning_rate', 0.05,0.5)\n",
    "    \n",
    "    opt_xgb = xgb.XGBClassifier (objective = 'binary:logistic', seed = 42, use_label_encoder=False, max_depth = max_depth,\n",
    "                                 learning_rate = learning_rate, min_child_weight = min_child_weight, gamma = gamma,\n",
    "                                 colsample_bytree = colsample_bytree, scale_pos_weight = scale_pos_weight)\n",
    "\n",
    "    score = cross_val_score(opt_xgb, x, y, n_jobs=4, cv=5, scoring = 'recall')\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ac7f576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value is : \n",
      "0.8395886222582728\n"
     ]
    }
   ],
   "source": [
    "# Getting the best score:\n",
    "print(f\"The best value is : \\n{study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ce54307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'max_depth': 3, 'min_child_weight': 4, 'gamma': 0.31697002808481123, 'colsample_bytree': 0.732879490463523, 'scale_pos_weight': 11, 'learning_rate': 0.13164217591978739}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9098b",
   "metadata": {},
   "source": [
    "# \n",
    "## Training the new model with the OPTUNA optimized hyperparameters¶\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07ec471e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-aucpr:0.22539\n",
      "[1]\tvalidation_0-aucpr:0.28210\n",
      "[2]\tvalidation_0-aucpr:0.29818\n",
      "[3]\tvalidation_0-aucpr:0.31167\n",
      "[4]\tvalidation_0-aucpr:0.31075\n",
      "[5]\tvalidation_0-aucpr:0.31359\n",
      "[6]\tvalidation_0-aucpr:0.31306\n",
      "[7]\tvalidation_0-aucpr:0.32235\n",
      "[8]\tvalidation_0-aucpr:0.32601\n",
      "[9]\tvalidation_0-aucpr:0.32682\n",
      "[10]\tvalidation_0-aucpr:0.33236\n",
      "[11]\tvalidation_0-aucpr:0.33258\n",
      "[12]\tvalidation_0-aucpr:0.33780\n",
      "[13]\tvalidation_0-aucpr:0.33967\n",
      "[14]\tvalidation_0-aucpr:0.34062\n",
      "[15]\tvalidation_0-aucpr:0.34190\n",
      "[16]\tvalidation_0-aucpr:0.34405\n",
      "[17]\tvalidation_0-aucpr:0.34555\n",
      "[18]\tvalidation_0-aucpr:0.35020\n",
      "[19]\tvalidation_0-aucpr:0.35085\n",
      "[20]\tvalidation_0-aucpr:0.35150\n",
      "[21]\tvalidation_0-aucpr:0.35198\n",
      "[22]\tvalidation_0-aucpr:0.35322\n",
      "[23]\tvalidation_0-aucpr:0.35440\n",
      "[24]\tvalidation_0-aucpr:0.35442\n",
      "[25]\tvalidation_0-aucpr:0.35609\n",
      "[26]\tvalidation_0-aucpr:0.35721\n",
      "[27]\tvalidation_0-aucpr:0.35787\n",
      "[28]\tvalidation_0-aucpr:0.35819\n",
      "[29]\tvalidation_0-aucpr:0.35938\n",
      "[30]\tvalidation_0-aucpr:0.35958\n",
      "[31]\tvalidation_0-aucpr:0.35977\n",
      "[32]\tvalidation_0-aucpr:0.36030\n",
      "[33]\tvalidation_0-aucpr:0.36079\n",
      "[34]\tvalidation_0-aucpr:0.36122\n",
      "[35]\tvalidation_0-aucpr:0.36128\n",
      "[36]\tvalidation_0-aucpr:0.36243\n",
      "[37]\tvalidation_0-aucpr:0.36246\n",
      "[38]\tvalidation_0-aucpr:0.36292\n",
      "[39]\tvalidation_0-aucpr:0.36329\n",
      "[40]\tvalidation_0-aucpr:0.36376\n",
      "[41]\tvalidation_0-aucpr:0.36403\n",
      "[42]\tvalidation_0-aucpr:0.36406\n",
      "[43]\tvalidation_0-aucpr:0.36435\n",
      "[44]\tvalidation_0-aucpr:0.36538\n",
      "[45]\tvalidation_0-aucpr:0.36541\n",
      "[46]\tvalidation_0-aucpr:0.36566\n",
      "[47]\tvalidation_0-aucpr:0.36567\n",
      "[48]\tvalidation_0-aucpr:0.36582\n",
      "[49]\tvalidation_0-aucpr:0.36598\n",
      "[50]\tvalidation_0-aucpr:0.36620\n",
      "[51]\tvalidation_0-aucpr:0.36628\n",
      "[52]\tvalidation_0-aucpr:0.36647\n",
      "[53]\tvalidation_0-aucpr:0.36696\n",
      "[54]\tvalidation_0-aucpr:0.36709\n",
      "[55]\tvalidation_0-aucpr:0.36712\n",
      "[56]\tvalidation_0-aucpr:0.36717\n",
      "[57]\tvalidation_0-aucpr:0.36729\n",
      "[58]\tvalidation_0-aucpr:0.36758\n",
      "[59]\tvalidation_0-aucpr:0.36776\n",
      "[60]\tvalidation_0-aucpr:0.36776\n",
      "[61]\tvalidation_0-aucpr:0.36790\n",
      "[62]\tvalidation_0-aucpr:0.36790\n",
      "[63]\tvalidation_0-aucpr:0.36794\n",
      "[64]\tvalidation_0-aucpr:0.36799\n",
      "[65]\tvalidation_0-aucpr:0.36817\n",
      "[66]\tvalidation_0-aucpr:0.36822\n",
      "[67]\tvalidation_0-aucpr:0.36812\n",
      "[68]\tvalidation_0-aucpr:0.36810\n",
      "[69]\tvalidation_0-aucpr:0.36819\n",
      "[70]\tvalidation_0-aucpr:0.36823\n",
      "[71]\tvalidation_0-aucpr:0.36839\n",
      "[72]\tvalidation_0-aucpr:0.36842\n",
      "[73]\tvalidation_0-aucpr:0.36856\n",
      "[74]\tvalidation_0-aucpr:0.36860\n",
      "[75]\tvalidation_0-aucpr:0.36855\n",
      "[76]\tvalidation_0-aucpr:0.36854\n",
      "[77]\tvalidation_0-aucpr:0.36852\n",
      "[78]\tvalidation_0-aucpr:0.36861\n",
      "[79]\tvalidation_0-aucpr:0.36861\n",
      "[80]\tvalidation_0-aucpr:0.36864\n",
      "[81]\tvalidation_0-aucpr:0.36878\n",
      "[82]\tvalidation_0-aucpr:0.36878\n",
      "[83]\tvalidation_0-aucpr:0.36897\n",
      "[84]\tvalidation_0-aucpr:0.36895\n",
      "[85]\tvalidation_0-aucpr:0.36911\n",
      "[86]\tvalidation_0-aucpr:0.36914\n",
      "[87]\tvalidation_0-aucpr:0.36899\n",
      "[88]\tvalidation_0-aucpr:0.36900\n",
      "[89]\tvalidation_0-aucpr:0.36907\n",
      "[90]\tvalidation_0-aucpr:0.36909\n",
      "[91]\tvalidation_0-aucpr:0.36917\n",
      "[92]\tvalidation_0-aucpr:0.36920\n",
      "[93]\tvalidation_0-aucpr:0.36914\n",
      "[94]\tvalidation_0-aucpr:0.36939\n",
      "[95]\tvalidation_0-aucpr:0.36939\n",
      "[96]\tvalidation_0-aucpr:0.36955\n",
      "[97]\tvalidation_0-aucpr:0.36953\n",
      "[98]\tvalidation_0-aucpr:0.36951\n",
      "[99]\tvalidation_0-aucpr:0.36963\n",
      "Sensitivity= 83.96791187739464 %\n"
     ]
    }
   ],
   "source": [
    "#CREATE OPTIMIZED XGBOOST model and FIT IT to the training data\n",
    "\n",
    "\n",
    "opt_xgb = xgb.XGBClassifier (objective = 'binary:logistic', seed = 42, use_label_encoder=False, learning_rate = 0.13164217591978739, \n",
    "                                max_depth = 3, min_child_weight = 4, colsample_bytree = 0.732879490463523, gamma = 0.31697002808481123,\n",
    "                               scale_pos_weight = 11)\n",
    "opt_xgb.fit (x_train, y_train, verbose = True, early_stopping_rounds = 10, eval_metric = 'aucpr', \n",
    "             eval_set = ([(x_test, y_test)]))\n",
    "\n",
    "#Calculating Accuracy of model\n",
    "\n",
    "optxgb_y_pred = opt_xgb.predict(x_test)\n",
    "\n",
    "#Sensitivity\n",
    "optxgb_sen = recall_score(y_test,optxgb_y_pred)*100\n",
    "print('Sensitivity=', optxgb_sen,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fa8fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "import pickle\n",
    "filename = 'xgb_optuna.sav'\n",
    "pickle.dump(opt_xgb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a39ff63",
   "metadata": {},
   "source": [
    "# \n",
    "# 5. Classification Tree\n",
    "# ============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41303a94",
   "metadata": {},
   "source": [
    "# \n",
    "## Create base model for hyperparameter tuning.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07ec471e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity= 27.873563218390807 %\n"
     ]
    }
   ],
   "source": [
    "#CREATE CLASSIFICATION TREE model and FIT IT to the training data\n",
    "\n",
    "\n",
    "classtree = DecisionTreeClassifier (random_state=42)\n",
    "classtree.fit (x_train, y_train)\n",
    "\n",
    "#Calculating Accuracy of model\n",
    "\n",
    "classtree_y_pred = classtree.predict(x_test)\n",
    "\n",
    "#Sensitivity\n",
    "classtree_sen = recall_score(y_test,classtree_y_pred)*100\n",
    "print('Sensitivity=', classtree_sen,'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ac248a",
   "metadata": {},
   "source": [
    "# \n",
    "# Cost Complexity Pruning using the Alpha value\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7af3aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing the parameters for the parameter grid\n",
    "\n",
    "#Cost complexity pruning alpha value.\n",
    "ccp_alpha = np. arange (0,0.99,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "501fd38c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': array([0.   , 0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008,\n",
      "       0.009, 0.01 , 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017,\n",
      "       0.018, 0.019, 0.02 , 0.021, 0.022, 0.023, 0.024, 0.025, 0.026,\n",
      "       0.027, 0.028, 0.029, 0.03 , 0.031, 0.032, 0.033, 0.034, 0.035,\n",
      "       0.036, 0.037, 0.038, 0.039, 0.04 , 0.041, 0.042, 0.043, 0.044,\n",
      "       0.045, 0.046, 0.047, 0.048, 0.049, 0.05 , 0.051, 0.052, 0.053,\n",
      "       0.054, 0.055, 0.056, 0.057, 0.058, 0.059, 0.06 , 0.061, 0.062,\n",
      "       0.063, 0.064, 0.065, 0.066, 0.067, 0.068, 0.069, 0.07 , 0.071,\n",
      "       0.072, 0.073, 0.074, 0.075, 0.076, 0.077, 0.078, 0.079, 0.08 ,\n",
      "       0.081, 0.082, 0.083, 0.084, 0.085, 0.086, 0.087, 0.088, 0.089,\n",
      "       0.09 , 0.091, 0.092, 0.093, 0.094, 0.095, 0.096, 0.097, 0.098,\n",
      "       0.099, 0.1  , 0.101, 0.102, 0.103, 0.104, 0.105, 0.106, 0.107,\n",
      "       0.108, 0.109, 0.11 , 0.111, 0.112, 0.113, 0.114, 0.115, 0.116,\n",
      "       0.117, 0.118, 0.119, 0.12 , 0.121, 0.122, 0.123, 0.124, 0.125,\n",
      "       0.126, 0.127, 0.128, 0.129, 0.13 , 0.131, 0.132, 0.133, 0.134,\n",
      "       0.135, 0.136, 0.137, 0.138, 0.139, 0.14 , 0.141, 0.142, 0.143,\n",
      "       0.144, 0.145, 0.146, 0.147, 0.148, 0.149, 0.15 , 0.151, 0.152,\n",
      "       0.153, 0.154, 0.155, 0.156, 0.157, 0.158, 0.159, 0.16 , 0.161,\n",
      "       0.162, 0.163, 0.164, 0.165, 0.166, 0.167, 0.168, 0.169, 0.17 ,\n",
      "       0.171, 0.172, 0.173, 0.174, 0.175, 0.176, 0.177, 0.178, 0.179,\n",
      "       0.18 , 0.181, 0.182, 0.183, 0.184, 0.185, 0.186, 0.187, 0.188,\n",
      "       0.189, 0.19 , 0.191, 0.192, 0.193, 0.194, 0.195, 0.196, 0.197,\n",
      "       0.198, 0.199, 0.2  , 0.201, 0.202, 0.203, 0.204, 0.205, 0.206,\n",
      "       0.207, 0.208, 0.209, 0.21 , 0.211, 0.212, 0.213, 0.214, 0.215,\n",
      "       0.216, 0.217, 0.218, 0.219, 0.22 , 0.221, 0.222, 0.223, 0.224,\n",
      "       0.225, 0.226, 0.227, 0.228, 0.229, 0.23 , 0.231, 0.232, 0.233,\n",
      "       0.234, 0.235, 0.236, 0.237, 0.238, 0.239, 0.24 , 0.241, 0.242,\n",
      "       0.243, 0.244, 0.245, 0.246, 0.247, 0.248, 0.249, 0.25 , 0.251,\n",
      "       0.252, 0.253, 0.254, 0.255, 0.256, 0.257, 0.258, 0.259, 0.26 ,\n",
      "       0.261, 0.262, 0.263, 0.264, 0.265, 0.266, 0.267, 0.268, 0.269,\n",
      "       0.27 , 0.271, 0.272, 0.273, 0.274, 0.275, 0.276, 0.277, 0.278,\n",
      "       0.279, 0.28 , 0.281, 0.282, 0.283, 0.284, 0.285, 0.286, 0.287,\n",
      "       0.288, 0.289, 0.29 , 0.291, 0.292, 0.293, 0.294, 0.295, 0.296,\n",
      "       0.297, 0.298, 0.299, 0.3  , 0.301, 0.302, 0.303, 0.304, 0.305,\n",
      "       0.306, 0.307, 0.308, 0.309, 0.31 , 0.311, 0.312, 0.313, 0.314,\n",
      "       0.315, 0.316, 0.317, 0.318, 0.319, 0.32 , 0.321, 0.322, 0.323,\n",
      "       0.324, 0.325, 0.326, 0.327, 0.328, 0.329, 0.33 , 0.331, 0.332,\n",
      "       0.333, 0.334, 0.335, 0.336, 0.337, 0.338, 0.339, 0.34 , 0.341,\n",
      "       0.342, 0.343, 0.344, 0.345, 0.346, 0.347, 0.348, 0.349, 0.35 ,\n",
      "       0.351, 0.352, 0.353, 0.354, 0.355, 0.356, 0.357, 0.358, 0.359,\n",
      "       0.36 , 0.361, 0.362, 0.363, 0.364, 0.365, 0.366, 0.367, 0.368,\n",
      "       0.369, 0.37 , 0.371, 0.372, 0.373, 0.374, 0.375, 0.376, 0.377,\n",
      "       0.378, 0.379, 0.38 , 0.381, 0.382, 0.383, 0.384, 0.385, 0.386,\n",
      "       0.387, 0.388, 0.389, 0.39 , 0.391, 0.392, 0.393, 0.394, 0.395,\n",
      "       0.396, 0.397, 0.398, 0.399, 0.4  , 0.401, 0.402, 0.403, 0.404,\n",
      "       0.405, 0.406, 0.407, 0.408, 0.409, 0.41 , 0.411, 0.412, 0.413,\n",
      "       0.414, 0.415, 0.416, 0.417, 0.418, 0.419, 0.42 , 0.421, 0.422,\n",
      "       0.423, 0.424, 0.425, 0.426, 0.427, 0.428, 0.429, 0.43 , 0.431,\n",
      "       0.432, 0.433, 0.434, 0.435, 0.436, 0.437, 0.438, 0.439, 0.44 ,\n",
      "       0.441, 0.442, 0.443, 0.444, 0.445, 0.446, 0.447, 0.448, 0.449,\n",
      "       0.45 , 0.451, 0.452, 0.453, 0.454, 0.455, 0.456, 0.457, 0.458,\n",
      "       0.459, 0.46 , 0.461, 0.462, 0.463, 0.464, 0.465, 0.466, 0.467,\n",
      "       0.468, 0.469, 0.47 , 0.471, 0.472, 0.473, 0.474, 0.475, 0.476,\n",
      "       0.477, 0.478, 0.479, 0.48 , 0.481, 0.482, 0.483, 0.484, 0.485,\n",
      "       0.486, 0.487, 0.488, 0.489, 0.49 , 0.491, 0.492, 0.493, 0.494,\n",
      "       0.495, 0.496, 0.497, 0.498, 0.499, 0.5  , 0.501, 0.502, 0.503,\n",
      "       0.504, 0.505, 0.506, 0.507, 0.508, 0.509, 0.51 , 0.511, 0.512,\n",
      "       0.513, 0.514, 0.515, 0.516, 0.517, 0.518, 0.519, 0.52 , 0.521,\n",
      "       0.522, 0.523, 0.524, 0.525, 0.526, 0.527, 0.528, 0.529, 0.53 ,\n",
      "       0.531, 0.532, 0.533, 0.534, 0.535, 0.536, 0.537, 0.538, 0.539,\n",
      "       0.54 , 0.541, 0.542, 0.543, 0.544, 0.545, 0.546, 0.547, 0.548,\n",
      "       0.549, 0.55 , 0.551, 0.552, 0.553, 0.554, 0.555, 0.556, 0.557,\n",
      "       0.558, 0.559, 0.56 , 0.561, 0.562, 0.563, 0.564, 0.565, 0.566,\n",
      "       0.567, 0.568, 0.569, 0.57 , 0.571, 0.572, 0.573, 0.574, 0.575,\n",
      "       0.576, 0.577, 0.578, 0.579, 0.58 , 0.581, 0.582, 0.583, 0.584,\n",
      "       0.585, 0.586, 0.587, 0.588, 0.589, 0.59 , 0.591, 0.592, 0.593,\n",
      "       0.594, 0.595, 0.596, 0.597, 0.598, 0.599, 0.6  , 0.601, 0.602,\n",
      "       0.603, 0.604, 0.605, 0.606, 0.607, 0.608, 0.609, 0.61 , 0.611,\n",
      "       0.612, 0.613, 0.614, 0.615, 0.616, 0.617, 0.618, 0.619, 0.62 ,\n",
      "       0.621, 0.622, 0.623, 0.624, 0.625, 0.626, 0.627, 0.628, 0.629,\n",
      "       0.63 , 0.631, 0.632, 0.633, 0.634, 0.635, 0.636, 0.637, 0.638,\n",
      "       0.639, 0.64 , 0.641, 0.642, 0.643, 0.644, 0.645, 0.646, 0.647,\n",
      "       0.648, 0.649, 0.65 , 0.651, 0.652, 0.653, 0.654, 0.655, 0.656,\n",
      "       0.657, 0.658, 0.659, 0.66 , 0.661, 0.662, 0.663, 0.664, 0.665,\n",
      "       0.666, 0.667, 0.668, 0.669, 0.67 , 0.671, 0.672, 0.673, 0.674,\n",
      "       0.675, 0.676, 0.677, 0.678, 0.679, 0.68 , 0.681, 0.682, 0.683,\n",
      "       0.684, 0.685, 0.686, 0.687, 0.688, 0.689, 0.69 , 0.691, 0.692,\n",
      "       0.693, 0.694, 0.695, 0.696, 0.697, 0.698, 0.699, 0.7  , 0.701,\n",
      "       0.702, 0.703, 0.704, 0.705, 0.706, 0.707, 0.708, 0.709, 0.71 ,\n",
      "       0.711, 0.712, 0.713, 0.714, 0.715, 0.716, 0.717, 0.718, 0.719,\n",
      "       0.72 , 0.721, 0.722, 0.723, 0.724, 0.725, 0.726, 0.727, 0.728,\n",
      "       0.729, 0.73 , 0.731, 0.732, 0.733, 0.734, 0.735, 0.736, 0.737,\n",
      "       0.738, 0.739, 0.74 , 0.741, 0.742, 0.743, 0.744, 0.745, 0.746,\n",
      "       0.747, 0.748, 0.749, 0.75 , 0.751, 0.752, 0.753, 0.754, 0.755,\n",
      "       0.756, 0.757, 0.758, 0.759, 0.76 , 0.761, 0.762, 0.763, 0.764,\n",
      "       0.765, 0.766, 0.767, 0.768, 0.769, 0.77 , 0.771, 0.772, 0.773,\n",
      "       0.774, 0.775, 0.776, 0.777, 0.778, 0.779, 0.78 , 0.781, 0.782,\n",
      "       0.783, 0.784, 0.785, 0.786, 0.787, 0.788, 0.789, 0.79 , 0.791,\n",
      "       0.792, 0.793, 0.794, 0.795, 0.796, 0.797, 0.798, 0.799, 0.8  ,\n",
      "       0.801, 0.802, 0.803, 0.804, 0.805, 0.806, 0.807, 0.808, 0.809,\n",
      "       0.81 , 0.811, 0.812, 0.813, 0.814, 0.815, 0.816, 0.817, 0.818,\n",
      "       0.819, 0.82 , 0.821, 0.822, 0.823, 0.824, 0.825, 0.826, 0.827,\n",
      "       0.828, 0.829, 0.83 , 0.831, 0.832, 0.833, 0.834, 0.835, 0.836,\n",
      "       0.837, 0.838, 0.839, 0.84 , 0.841, 0.842, 0.843, 0.844, 0.845,\n",
      "       0.846, 0.847, 0.848, 0.849, 0.85 , 0.851, 0.852, 0.853, 0.854,\n",
      "       0.855, 0.856, 0.857, 0.858, 0.859, 0.86 , 0.861, 0.862, 0.863,\n",
      "       0.864, 0.865, 0.866, 0.867, 0.868, 0.869, 0.87 , 0.871, 0.872,\n",
      "       0.873, 0.874, 0.875, 0.876, 0.877, 0.878, 0.879, 0.88 , 0.881,\n",
      "       0.882, 0.883, 0.884, 0.885, 0.886, 0.887, 0.888, 0.889, 0.89 ,\n",
      "       0.891, 0.892, 0.893, 0.894, 0.895, 0.896, 0.897, 0.898, 0.899,\n",
      "       0.9  , 0.901, 0.902, 0.903, 0.904, 0.905, 0.906, 0.907, 0.908,\n",
      "       0.909, 0.91 , 0.911, 0.912, 0.913, 0.914, 0.915, 0.916, 0.917,\n",
      "       0.918, 0.919, 0.92 , 0.921, 0.922, 0.923, 0.924, 0.925, 0.926,\n",
      "       0.927, 0.928, 0.929, 0.93 , 0.931, 0.932, 0.933, 0.934, 0.935,\n",
      "       0.936, 0.937, 0.938, 0.939, 0.94 , 0.941, 0.942, 0.943, 0.944,\n",
      "       0.945, 0.946, 0.947, 0.948, 0.949, 0.95 , 0.951, 0.952, 0.953,\n",
      "       0.954, 0.955, 0.956, 0.957, 0.958, 0.959, 0.96 , 0.961, 0.962,\n",
      "       0.963, 0.964, 0.965, 0.966, 0.967, 0.968, 0.969, 0.97 , 0.971,\n",
      "       0.972, 0.973, 0.974, 0.975, 0.976, 0.977, 0.978, 0.979, 0.98 ,\n",
      "       0.981, 0.982, 0.983, 0.984, 0.985, 0.986, 0.987, 0.988, 0.989])}\n"
     ]
    }
   ],
   "source": [
    "#Creating the parameter grid\n",
    "\n",
    "ct_param_grid = {'ccp_alpha':ccp_alpha}\n",
    "\n",
    "print (ct_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d194209a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: array([0.   , 0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008,\n",
       "       0.009, 0.01 , 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017,\n",
       "       0.018, 0.019, 0.02 , 0.021, 0.022, 0.023, 0.024, 0.025, 0.026,\n",
       "       0.027, 0.028, 0.029, 0.03 , 0.031, 0.032, 0.033, 0.034, 0.035,\n",
       "       0.036, 0.037, 0.038, 0.039, 0.04 , 0....\n",
       "       0.927, 0.928, 0.929, 0.93 , 0.931, 0.932, 0.933, 0.934, 0.935,\n",
       "       0.936, 0.937, 0.938, 0.939, 0.94 , 0.941, 0.942, 0.943, 0.944,\n",
       "       0.945, 0.946, 0.947, 0.948, 0.949, 0.95 , 0.951, 0.952, 0.953,\n",
       "       0.954, 0.955, 0.956, 0.957, 0.958, 0.959, 0.96 , 0.961, 0.962,\n",
       "       0.963, 0.964, 0.965, 0.966, 0.967, 0.968, 0.969, 0.97 , 0.971,\n",
       "       0.972, 0.973, 0.974, 0.975, 0.976, 0.977, 0.978, 0.979, 0.98 ,\n",
       "       0.981, 0.982, 0.983, 0.984, 0.985, 0.986, 0.987, 0.988, 0.989])},\n",
       "             scoring=&#x27;recall&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: array([0.   , 0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008,\n",
       "       0.009, 0.01 , 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017,\n",
       "       0.018, 0.019, 0.02 , 0.021, 0.022, 0.023, 0.024, 0.025, 0.026,\n",
       "       0.027, 0.028, 0.029, 0.03 , 0.031, 0.032, 0.033, 0.034, 0.035,\n",
       "       0.036, 0.037, 0.038, 0.039, 0.04 , 0....\n",
       "       0.927, 0.928, 0.929, 0.93 , 0.931, 0.932, 0.933, 0.934, 0.935,\n",
       "       0.936, 0.937, 0.938, 0.939, 0.94 , 0.941, 0.942, 0.943, 0.944,\n",
       "       0.945, 0.946, 0.947, 0.948, 0.949, 0.95 , 0.951, 0.952, 0.953,\n",
       "       0.954, 0.955, 0.956, 0.957, 0.958, 0.959, 0.96 , 0.961, 0.962,\n",
       "       0.963, 0.964, 0.965, 0.966, 0.967, 0.968, 0.969, 0.97 , 0.971,\n",
       "       0.972, 0.973, 0.974, 0.975, 0.976, 0.977, 0.978, 0.979, 0.98 ,\n",
       "       0.981, 0.982, 0.983, 0.984, 0.985, 0.986, 0.987, 0.988, 0.989])},\n",
       "             scoring=&#x27;recall&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'ccp_alpha': array([0.   , 0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008,\n",
       "       0.009, 0.01 , 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017,\n",
       "       0.018, 0.019, 0.02 , 0.021, 0.022, 0.023, 0.024, 0.025, 0.026,\n",
       "       0.027, 0.028, 0.029, 0.03 , 0.031, 0.032, 0.033, 0.034, 0.035,\n",
       "       0.036, 0.037, 0.038, 0.039, 0.04 , 0....\n",
       "       0.927, 0.928, 0.929, 0.93 , 0.931, 0.932, 0.933, 0.934, 0.935,\n",
       "       0.936, 0.937, 0.938, 0.939, 0.94 , 0.941, 0.942, 0.943, 0.944,\n",
       "       0.945, 0.946, 0.947, 0.948, 0.949, 0.95 , 0.951, 0.952, 0.953,\n",
       "       0.954, 0.955, 0.956, 0.957, 0.958, 0.959, 0.96 , 0.961, 0.962,\n",
       "       0.963, 0.964, 0.965, 0.966, 0.967, 0.968, 0.969, 0.97 , 0.971,\n",
       "       0.972, 0.973, 0.974, 0.975, 0.976, 0.977, 0.978, 0.979, 0.98 ,\n",
       "       0.981, 0.982, 0.983, 0.984, 0.985, 0.986, 0.987, 0.988, 0.989])},\n",
       "             scoring='recall', verbose=2)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the best alpha value using GridSearchCV\n",
    "# Creating the Grid with previously defined hyperparameters and fiting it to the train data\n",
    "\n",
    "ct_grid = GridSearchCV (estimator = classtree, param_grid = ct_param_grid, cv = 5, verbose = 2, n_jobs = -1 ,scoring = 'recall')\n",
    "ct_grid.fit (x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e7a64175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best parameters\n",
    "\n",
    "ct_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9098b",
   "metadata": {},
   "source": [
    "# \n",
    "## Training the new model with the GridSearchCV optimized hyperparameters¶\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07ec471e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity= 27.873563218390807 %\n"
     ]
    }
   ],
   "source": [
    "#CREATE OPTIMIZED CLASSIFICATION TREE model and FIT IT to the training data\n",
    "\n",
    "\n",
    "ct_grid = DecisionTreeClassifier (random_state=42, ccp_alpha = 0.0 )\n",
    "ct_grid.fit (x_train, y_train)\n",
    "\n",
    "#Calculating Accuracy of model\n",
    "\n",
    "ctgrid_y_pred = ct_grid.predict(x_test)\n",
    "\n",
    "#Sensitivity\n",
    "ctgrid_sen = recall_score(y_test,ctgrid_y_pred)*100\n",
    "print('Sensitivity=', ctgrid_sen,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fa8fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "import pickle\n",
    "filename = 'ct_grid.sav'\n",
    "pickle.dump(ct_grid, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea1181b",
   "metadata": {},
   "source": [
    "# \n",
    "## Hyperparameter tuning with OPTUNA for Classification Tree.\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "592f2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing optuna library.\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "04b2f124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-13 16:27:18,175]\u001b[0m A new study created in memory with name: no-name-d9c5e52e-e856-47eb-81ad-ed56d8ff8bfd\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 16:27:26,051]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'ccp_alpha': 0.5854986844801698}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 16:27:32,091]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'ccp_alpha': 0.18614567039040242}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 16:27:37,883]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'ccp_alpha': 0.8449850291151026}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 16:27:43,751]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'ccp_alpha': 0.3834101737002091}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 16:27:49,821]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'ccp_alpha': 0.8862187811076142}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 16:27:55,978]\u001b[0m Trial 5 finished with value: 0.0 and parameters: {'ccp_alpha': 0.6265852182044375}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 16:28:01,957]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'ccp_alpha': 0.9493956080976649}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 16:28:08,182]\u001b[0m Trial 7 finished with value: 0.0 and parameters: {'ccp_alpha': 0.6230088716219913}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 16:28:14,243]\u001b[0m Trial 8 finished with value: 0.0 and parameters: {'ccp_alpha': 0.7111079536978091}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 16:28:20,158]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {'ccp_alpha': 0.4275213366188904}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 16:28:25,996]\u001b[0m Trial 10 finished with value: 0.0 and parameters: {'ccp_alpha': 0.0648694652879025}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 16:28:31,854]\u001b[0m Trial 11 finished with value: 0.0 and parameters: {'ccp_alpha': 0.19946152844312204}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 16:28:38,197]\u001b[0m Trial 12 finished with value: 0.0 and parameters: {'ccp_alpha': 0.2459249030303205}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 16:28:44,056]\u001b[0m Trial 13 finished with value: 0.0 and parameters: {'ccp_alpha': 0.003638790186845764}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2022-11-13 16:28:50,006]\u001b[0m Trial 14 finished with value: 0.0 and parameters: {'ccp_alpha': 0.2989870647006979}. Best is trial 0 with value: 0.0.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    ccp_alpha = trial.suggest_float ('ccp_alpha', 0,0.99)\n",
    "    \n",
    "    \n",
    "    opt_ct = DecisionTreeClassifier (random_state=42, ccp_alpha = ccp_alpha)\n",
    "\n",
    "    score = cross_val_score(opt_ct, x, y, n_jobs=4, cv=5, scoring = 'recall')\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8ac7f576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value is : \n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Getting the best score:\n",
    "print(f\"The best value is : \\n{study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2ce54307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'ccp_alpha': 0.5854986844801698}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9098b",
   "metadata": {},
   "source": [
    "# \n",
    "## Training the new model with the OPTUNA optimized hyperparameters¶\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07ec471e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity= 0.0 %\n"
     ]
    }
   ],
   "source": [
    "#CREATE OPTIMIZED CLASSIFICATION TREE model and FIT IT to the training data\n",
    "\n",
    "\n",
    "opt_ct = DecisionTreeClassifier (random_state=42, ccp_alpha = 0.5854986844801698)\n",
    "opt_ct.fit (x_train, y_train)\n",
    "#Calculating Accuracy of model\n",
    "\n",
    "optct_y_pred = opt_ct.predict(x_test)\n",
    "\n",
    "#Sensitivity\n",
    "optct_sen = recall_score(y_test,optct_y_pred)*100\n",
    "print('Sensitivity=', optct_sen,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fa8fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "import pickle\n",
    "filename = 'ct_optuna.sav'\n",
    "pickle.dump(opt_ct, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c5cd79",
   "metadata": {},
   "source": [
    "# \n",
    "# Models scores comparision table\n",
    "# =============================================================\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14f80a11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scores</th>\n",
       "      <th>Logistic Regresion</th>\n",
       "      <th>K-Nearest Neighbor</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>Classification Tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base_Model</td>\n",
       "      <td>14.475575</td>\n",
       "      <td>7.483238</td>\n",
       "      <td>12.954981</td>\n",
       "      <td>9.530651</td>\n",
       "      <td>27.873563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GridSearchCV</td>\n",
       "      <td>14.475575</td>\n",
       "      <td>14.307950</td>\n",
       "      <td>3.148946</td>\n",
       "      <td>54.525862</td>\n",
       "      <td>27.873563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OPTUNA</td>\n",
       "      <td>[]</td>\n",
       "      <td>14.391762</td>\n",
       "      <td>2.155172</td>\n",
       "      <td>83.967912</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Scores Logistic Regresion  K-Nearest Neighbor  Random Forest  \\\n",
       "0    Base_Model          14.475575            7.483238      12.954981   \n",
       "1  GridSearchCV          14.475575           14.307950       3.148946   \n",
       "2        OPTUNA                 []           14.391762       2.155172   \n",
       "\n",
       "     XGBoost  Classification Tree  \n",
       "0   9.530651            27.873563  \n",
       "1  54.525862            27.873563  \n",
       "2  83.967912             0.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a table to compare the scores of the base and optimized models.\n",
    "\n",
    "logis = [lr_sen, lrgrid_sen,optlr_sen]\n",
    "knei = [knn_sen, gridknn_sen, optknn_sen]\n",
    "rando = [rf_sen, grid2rf_sen, optrf_sen]\n",
    "xgbo = [xgb_sen, xgbgrid2_sen, optxgb_sen]\n",
    "classif = [classtree_sen, ctgrid_sen,optct_sen]\n",
    "scores = ['Base_Model', 'GridSearchCV', 'OPTUNA']\n",
    "\n",
    "data = list(zip(scores, logis, knei, rando, xgbo, classif))\n",
    "eval_scores = pd.DataFrame(data, columns=['Scores','Logistic Regresion', 'K-Nearest Neighbor', 'Random Forest', 'XGBoost', \n",
    "                                          'Classification Tree'])\n",
    "eval_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c38407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that the XGBoost is the model that performed the best after optimization. We'll try to improve the sensitivity \n",
    "#even more using model esemble."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
